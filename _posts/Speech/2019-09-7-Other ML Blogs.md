---
layout: post
title: Some Other ML Blogs
categories: [meta]
mathjax: false
---
While it is typically best to learn formally from a textbook, course or paper, sometimes well written blogs can fast pace your progress in a particular sub-field or area. I recently stumbled upon a nice list of ML blogs (with some sprinkling of differential geometry and optimization) on [reddit](https://www.reddit.com/r/MachineLearning/comments/azmo98/d_indepth_blogs_discussing_ml_and_the_math/) and have tried to consolidate it here and add to it a little. Almost all of these blogs are by professional scientists and researchers (in contrast to many hobbyist or newbies blogs you find on medium). This list is aimed at grad students and aspiring researchers like me and contains blogs which mainly tackle academic topics. You should think of these blogs as 'mini-papers' or 'lecture notes' as opposed to an informal blog to get the most out of them. Further note that due to complexity of the topics many of these blogs will assume that you at least have the equivalent mathematical proficiency to an undergrad in engineering or computer science. So, if you are still new to machine learning and/or not looking to get into machine learning research, this list is probably not for you. 

## [Lil'Log](https://lilianweng.github.io/lil-log/)
Lillian Weng blogs provide are one of the most comprehensive overview of the field written in a very simple language. I have been a regular reader of her for at least a year now and even in areas where I had no prior knowledge, her blogs have been easy to understand. Her blogs on flow [based generative models](https://lilianweng.github.io/lil-log/2018/10/13/flow-based-deep-generative-models.html) and [attention mechanisms](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html) are highly recommended.


## [The Spectator](http://blog.shakirm.com/)
Spectator is the blog of [Shakir Muhammad](http://shakirm.com/). Shakir is a Deepmind Scientist and is not only a proficient researcher but also has been contributing to development of ML community. His technical blogs mainly revolve around probabilistic perspective to machine learning, generative models and bayesian analysis. I will also recommend going through Shakir's talks (available on his websites) to those looking to get started in probabilistic machine learning and generative models. 
His 'Machine Learning Trick Of the Day' series in particular is very exciting and shows how little changes can help change the orientation of problems and make them easier (or harder) to solve. 

## [Off The Convex Path](http://www.offconvex.org/)
This is the blog of [Sanjeev Arora](https://www.cs.princeton.edu/~arora/) and his collaborators and focuses heavily on optimization and theoretical machine learning. It generally features elucidation of their own research work. If you are someone looking to get into theoretical ML, this is a good blog to wet your toes in. 

## [inFRENCe](https://www.inference.vc/)
There are few people who are as good at illustrating hard-to-digest stuff as Ferenc Husz√°r. I first found Ferenc's blog when I was trying to understand dilated convolutions in Wavenet paper and Ferenc imparted a knowledge equivalent of several papers in a single blog post. I am not the only one who is fan if inFRENCe by the way. 

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">I&#39;ve never been accused of being over generous with compliments on technical writing. But <a href="https://twitter.com/fhuszar?ref_src=twsrc%5Etfw">@fhuszar</a> just always sets such a consistently high bar. He out-does himself with this marvelous blog post explaining Judea-Pearl-style do-Calculus <a href="https://t.co/0ii1yNyWzt">https://t.co/0ii1yNyWzt</a></p>&mdash; Zachary Lipton (@zacharylipton) <a href="https://twitter.com/zacharylipton/status/999748967767343104?ref_src=twsrc%5Etfw">May 24, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


## [Ben Racht's Blog: Arg Min](http://www.argmin.net/)
Ben is the other half of Ali Rahimi's infamous NIPS Test Of Time Award Talk ['Machine Learning Has Become Alchemy'](http://www.argmin.net/2017/12/11/alchemy-addendum/) and a proficient researcher. Just like Sanjeev et al. Ben also leans towards theoretical machine learning and this reflects in his blogs (in fact, Ben's [first post](http://www.argmin.net/2016/03/24/saddles-again/) was on Sanjeev's blog). Ben also has a nice primer on reinforcement learning. 

## [Justin Domke's Weblog](https://justindomke.wordpress.com/)
One of the blogs I came to know about via the mentioned subreddit and having read two blogs, this seems like a great blog for light reading. There is a nice mix of intuition and math and in particular, I loved the [blog](https://justindomke.wordpress.com/2017/11/16/a-divergence-bound-for-hybrids-of-mcmc-and-variational-inference-and/) on combining variational inference and MCMC.

## [Parameter Free](https://parameterfree.com/)
This blog is on paramater free optimization by [Francesco Orabona](http://francesco.orabona.com/). Again, an undiscovered blog for me, and I have not been able to read a lot of it, but if you are someone who is into optimization theory and not afraid of mathematics, you should enjoy this blog. 

## [Agustinus Kristiadl's Blog](https://wiseodd.github.io/techblog/)
Augustinus's is a PhD student with Philipp Hanning. This is one of the blog I have come to know about through the reddit. After a cursory glance,his blog has a nice blend of mathematical and intuitive reasoning, however, he does not always set up things very well, so, if you have zero prior knowledge about the matter, it might be a little difficult for you to fully follow his blogs. 


## Honorable Mentions
- [Rohan Varma](https://rohanvarma.me/about/) takes your run of the mill ideas and provides a different perspective to them. Nice blog for people starting in ML. 
- [Thibaut Lienart](https://tlienart.github.io/) also has some nice notes on Bayesian Machine Learning, optimization and Julia Language. 
- [Sorta Insightful](https://www.alexirpan.com/about/) has some great content but does not appear to have much structure which makes browsing hard.
- [Hadrienj's posts](https://hadrienj.github.io/posts/) contain some nice helping material for pre-ML stuff (linear algebra and probability).
- [The Information Structuralist]() blogs are also quite useful but a little bit thick and not suited for light reading. 

## Some Usual Suspects
Following are the blogs which are quite popular and generally known to almost anybody active in ML, so, have not cared to add details about them. 

- Chris Olah's [blog](https://colah.github.io/)
- Sebastian Ruder's [blog](http://ruder.io/)
- Karpathy's blogs - [old](http://karpathy.github.io/), [new](https://medium.com/@karpathy)
- Berkeley Artificial Intelligence Research [Blog](https://bair.berkeley.edu/blog/)
- [Gradient](https://thegradient.pub/) by Stanford Artificial Intelligence Laboratory
- [Distill](www.distill.pub)
- Industrial blogs
  - Google's AI [Blog](https://ai.googleblog.com/)
  - OpenAI [Blog](https://openai.com/blog/)
  - Deepmind [Blog](https://deepmind.com/blog)
  
## More Blogs
If you still want more blogs, just search google for 'machine learning blogs' and you can find tons of list and new blogs. 